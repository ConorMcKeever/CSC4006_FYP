from nltk.tokenize import sent_tokenize, word_tokenize

#needs to take in a list of sentences ,clean it into sentence tokens and put into a single list
